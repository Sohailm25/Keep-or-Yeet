# -*- coding: utf-8 -*-
"""UPDATED MLModel (Waste Data v2 3 CLASSES)(MobileNet).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16q7-R2IrhHtMq9GEblbgawj8iiRJKr-Q

# SET TENSORFLOW VERSION + IMPORTS
"""



# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

from __future__ import absolute_import, division, print_function, unicode_literals
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import zipfile 
import IPython.display as display
from PIL import Image
AUTOTUNE = tf.data.experimental.AUTOTUNE

"""#IMPORTING KAGGLE INTO GOOGLE COLLAB

Here I'm simply trying to take the api token connected to my kaggle account and dumping into the collab
"""

!mkdir -p ~/.kaggle

"""Need to download a Kaggle.json from the kaggle website under 'My Account'"""

from google.colab import files
files.upload()

!cp kaggle.json ~/.kaggle/

"""#DOWNLOADING THE DATASET FROM KAGGLE"""

!kaggle datasets download -d sapal6/waste-classification-data-v2 -p /content

"""Opening the saved ZIP file and extracting the contents"""

local_zip = '/content/waste-classification-data-v2.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/waste-classification-data')
zip_ref.close()

dir_name = "/content/waste-classification-data/DATASET/TEST/N"
test = os.listdir(dir_name)

for item in test:
    if item.endswith(".cfm") or item.endswith(".webp"):
        os.remove(os.path.join(dir_name, item))

"""#DATASET OBJECT METHOD

##DATA PREPROCESSING WITH tf.DATA + DATA AUGMENTATION
"""

import pathlib

data_dir_train = pathlib.Path('/content/waste-classification-data/DATASET/TRAIN')
image_count_train = len(list(data_dir_train.glob('*/*.jpg')))
image_count_train

data_dir_test = pathlib.Path('/content/waste-classification-data/DATASET/TEST')
image_count_test = len(list(data_dir_test.glob('*/*.jpg')))
image_count_test

CLASS_NAMES = np.array([item.name for item in data_dir_train.glob('*') if item.name != "LICENSE.txt"])
CLASS_NAMES

list_ds_train = tf.data.Dataset.list_files(str(data_dir_train/'*/*'))
list_ds_test = tf.data.Dataset.list_files(str(data_dir_test/'*/*'))

for f in list_ds_test.take(5):
  print(f.numpy())

"""Creating the (Image,Label) pairs + Formatting the shape of image"""

def get_label(file_path):
  # convert the path to a list of path components
  parts = tf.strings.split(file_path, os.path.sep)
  # The second to last is the class-directory
  return parts[-2] == CLASS_NAMES

def decode_img(img):
  # convert the compressed string to a 3D uint8 tensor
  img = tf.image.decode_jpeg(img, channels=3)
  # Use `convert_image_dtype` to convert to floats in the [0,1] range.
  img = tf.image.convert_image_dtype(img, tf.float32)
  # resize the image to the desired size.
  return tf.image.resize(img, [224, 224])

def aug_decode_img(img):
  img = tf.image.decode_jpeg(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.float32) # Cast and normalize the image to [0,1]
  #img = tf.image.rgb_to_grayscale(img) (FLATTENS IT TO 1 CHANNEL, BC RGB IS GONE)
  img = tf.image.random_flip_left_right(img)
  img = tf.image.random_flip_up_down(img)
  img = tf.image.random_brightness(img, max_delta=0.5) # Random brightness

  return tf.image.resize(img, [224,224])

def process_path(file_path):
  label = get_label(file_path)
  # load the raw data from the file as a string
  img = tf.io.read_file(file_path)
  img = decode_img(img)
  return img, label

def aug_process_path(file_path):
  label = get_label(file_path)
  # load the raw data from the file as a string
  img = tf.io.read_file(file_path)
  img = aug_decode_img(img)
  return img, label

"""Apply this transformation function to every image in the dataset"""

# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.
labeled_ds_train = list_ds_train.map(process_path, num_parallel_calls=AUTOTUNE)
labeled_ds_test = list_ds_test.map(process_path, num_parallel_calls=AUTOTUNE)

"""Create the augmented image dataset"""

aug_labeled_ds_train = list_ds_train.map(aug_process_path, num_parallel_calls=AUTOTUNE)
aug_labeled_ds_test  = list_ds_test.map(aug_process_path, num_parallel_calls=AUTOTUNE)

for image, label in labeled_ds_train.take(1):
  print("Image shape: ", image.numpy().shape)
  print("Label: ", label.numpy())

for image, label in aug_labeled_ds_train.take(1):
  print("Image shape: ", image.numpy().shape)
  print("Label: ", label.numpy())

"""Shuffle and batch the data"""

def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):
  # This is a small dataset, only load it once, and keep it in memory.
  # use `.cache(filename)` to cache preprocessing work for datasets that don't
  # fit in memory.
  if cache:
    if isinstance(cache, str):
      ds = ds.cache(cache)
    else:
      ds = ds.cache()

  ds = ds.shuffle(buffer_size=shuffle_buffer_size)

  # Repeat forever
  ds = ds.repeat()

  ds = ds.batch(100)

  # `prefetch` lets the dataset fetch batches in the background while the model
  # is training.
  ds = ds.prefetch(buffer_size=AUTOTUNE)

  return ds

train_ds = prepare_for_training(labeled_ds_train)
test_ds = prepare_for_training(labeled_ds_test)

image_batch, label_batch = next(iter(train_ds))
image_batch, label_batch = next(iter(test_ds))

aug_train_ds = prepare_for_training(aug_labeled_ds_train)
aug_test_ds = prepare_for_training(aug_labeled_ds_test)

aug_image_batch, aug_label_batch = next(iter(aug_train_ds))
aug_image_batch, aug_label_batch = next(iter(aug_test_ds))

def show_batch(image_batch, label_batch):
  plt.figure(figsize=(10,10))
  for n in range(25):
      ax = plt.subplot(5,5,n+1)
      plt.imshow(image_batch[n])
      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())
      plt.axis('off')

"""Check its all being displayed"""

image_batch.shape

show_batch(aug_image_batch.numpy(), aug_label_batch.numpy())

"""## CREATING THE CNN MODEL

### Loading the Pre-Trained Conv Neural Network
"""

IMG_SHAPE = (224,224,3)

# Create the base model from the pre-trained model MobileNet V2
base_model = tf.keras.applications.MobileNetV2(input_shape = IMG_SHAPE,
                                               include_top=False,        # this will follow the common practice and only include the very last layer before the flatten operation.
                                                                        # Called the bottleneck layer, retains the generality of the model,
                                                                        # we will make the top layers specific to our model
                                               weights='imagenet')

feature_batch = base_model(image_batch)
print(feature_batch.shape)

"""### Feature Extraction

Need to **freeze the convolutional base layers** of MobileNet so that they can't be updated during training, and keep the original weights determined by the MobileNet Model.
"""

base_model.trainable = False

base_model.summary()

"""Add GlobalAveragePooling2D layer"""

global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
feature_batch_average = global_average_layer(feature_batch)
print(feature_batch_average.shape)

"""Add Dense Layer
>Activation function not needed because it outputs in LOGITS (so need to convert from logits to a readable prediction value)
"""

prediction_layer = tf.keras.layers.Dense(3, activation='softmax')
prediction_batch = prediction_layer(feature_batch_average)
print(prediction_batch.shape)

"""Stack the feature extractor (the base model) and these last 2 layers"""

new_model = tf.keras.Sequential([
  base_model,
  global_average_layer,
  tf.keras.layers.Dropout(0.15),
  prediction_layer
])

"""### Compiling the model"""

base_learning_rate = 0.0001
new_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

"""Notice how there are 2.3 Million total parameters, but ONLY 2.5 K are TRAINABLE (because we froze the other layers)"""

new_model.summary()

"""### Training the Model"""

model_without_aug = new_model
model_with_aug = new_model
model_with_both = new_model

initial_epochs = 15
validation_steps=20

"""#### Model without Augmentation"""

#loss0,accuracy0 = model_without_aug.evaluate(test_ds, steps = validation_steps)

#print("initial loss: {:.2f}".format(loss0))
#print("initial accuracy: {:.2f}".format(accuracy0))

# #new_history = model_without_aug.fit(train_ds,
#                     epochs=initial_epochs,
#                     steps_per_epoch = 88,
#                     validation_steps=9,
#                     validation_data=test_ds)

"""####Model with Augmentation"""

#loss1,accuracy1 = model_with_aug.evaluate(aug_test_ds, steps = validation_steps)

#print("initial loss: {:.2f}".format(loss1))
#print("initial accuracy: {:.2f}".format(accuracy1))

# #aug_new_history = model_with_aug.fit(aug_train_ds,
#                     epochs=initial_epochs,
#                     steps_per_epoch = 88,
#                     validation_steps=9,
#                     validation_data=aug_test_ds)

"""#### Model with Both"""

loss2,accuracy2 = model_with_both.evaluate(test_ds, steps = validation_steps)

print("initial loss: {:.2f}".format(loss2))
print("initial accuracy: {:.2f}".format(accuracy2))

beforeaug_both_history = model_with_aug.fit(train_ds,
                    epochs=initial_epochs,
                    steps_per_epoch = 225,
                    validation_steps=28,
                    validation_data=test_ds)

both_new_history = model_with_aug.fit(aug_train_ds,
                    epochs=initial_epochs,
                    steps_per_epoch = 225,
                    validation_steps=28,
                    validation_data=test_ds)

"""### Learning Curves

#### Without Augmentation
"""

# #acc = new_history.history['accuracy']
# val_acc = new_history.history['val_accuracy']

# loss = new_history.history['loss']
# val_loss = new_history.history['val_loss']

# plt.figure(figsize=(8, 8))
# plt.subplot(2, 1, 1)
# plt.plot(acc, label='Training Accuracy')
# plt.plot(val_acc, label='Validation Accuracy')
# plt.legend(loc='lower right')
# plt.ylabel('Accuracy')
# plt.ylim([min(plt.ylim()),1])
# plt.title('Training and Validation Accuracy')

# plt.subplot(2, 1, 2)
# plt.plot(loss, label='Training Loss')
# plt.plot(val_loss, label='Validation Loss')
# plt.legend(loc='upper right')
# plt.ylabel('Cross Entropy')
# plt.ylim([0,1.0])
# plt.title('Training and Validation Loss')
# plt.xlabel('epoch')
# plt.show()

"""#### With Augmentation"""

# #acc = aug_new_history.history['accuracy']
# val_acc = aug_new_history.history['val_accuracy']

# loss = aug_new_history.history['loss']
# val_loss = aug_new_history.history['val_loss']

# plt.figure(figsize=(8, 8))
# plt.subplot(2, 1, 1)
# plt.plot(acc, label='Training Accuracy')
# plt.plot(val_acc, label='Validation Accuracy')
# plt.legend(loc='lower right')
# plt.ylabel('Accuracy')
# plt.ylim([min(plt.ylim()),1])
# plt.title('Training and Validation Accuracy')

# plt.subplot(2, 1, 2)
# plt.plot(loss, label='Training Loss')
# plt.plot(val_loss, label='Validation Loss')
# plt.legend(loc='upper right')
# plt.ylabel('Cross Entropy')
# plt.ylim([0,1.0])
# plt.title('Training and Validation Loss')
# plt.xlabel('epoch')
# plt.show()

"""#### BOTH NORMAL AND AUG"""

acc = both_new_history.history['accuracy']
val_acc = both_new_history.history['val_accuracy']

loss = both_new_history.history['loss']
val_loss = both_new_history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

# from google.colab import drive
# drive.mount('/content/drive')

# model_with_aug.save_weights('waste_class_weights_1000epochs.h5')
# model_with_aug.save('waste_class_model_1000epochs.h5')

"""### Fine Tuning

Unfreezing Layers
"""

base_model.trainable = True

# Let's take a look to see how many layers are in the base model
print("Number of layers in the base model: ", len(base_model.layers))

# Fine-tune from this layer onwards
fine_tune_at = 100

# Freeze all the layers before the `fine_tune_at` layer
for layer in base_model.layers[:fine_tune_at]:
  layer.trainable =  False

"""compile the model again using a much lower learning rate"""

model_with_aug.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
              optimizer = tf.keras.optimizers.SGD(learning_rate=base_learning_rate, momentum=0.9),
              metrics=['accuracy'])

model_with_aug.summary()

len(model_with_aug.trainable_variables)

fine_tune_epochs = 1000
total_epochs =  initial_epochs + fine_tune_epochs

history_fine = model_with_aug.fit(train_ds,
                         epochs=total_epochs,
                         steps_per_epoch = 225,
                         validation_steps=28,
                         initial_epoch = both_new_history.epoch[-1],
                         validation_data=test_ds)

acc += history_fine.history['accuracy']
val_acc += history_fine.history['val_accuracy']

loss += history_fine.history['loss']
val_loss += history_fine.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.ylim([0.8, 1])
plt.plot([initial_epochs-1,initial_epochs-1],
          plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.ylim([0, 1.0])
plt.plot([initial_epochs-1,initial_epochs-1],
         plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

"""# New Section

This will export the saved model as a SavedModel format
"""

model_with_aug.save('wasteV2model_BASELR_1000epochs_finetune_model')

"""###MAKING PREDICTIONS"""

from keras.preprocessing import image

pred_test_dir = '/content/IMG_3452.jpg'

test_image = image.load_img(pred_test_dir, target_size=(224,224))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, vaxis=0)

test_image = test_image.reshape(1,224,224,3)

"""HOW THE PROBABILITY DISTRIBUTION ARRAY IS SETUP
>[ORGANIC, RECYCLE, NONRECYCLABLE]
"""

predictions = new_model.predict(test_image, batch_size=1)
print(predictions)

print(CLASS_NAMES[np.argmax(predictions[0])])

"""#IMAGE GENERATOR METHOD (USE ONLY FOR REFERENCE)
>(THIS IS THE METHOD NOT USING DATASET OBJECTS IN TENSORFLOW, NOR DOES IT USE A PRETRAINED CNN)

## LOADING IN DATA
"""

# train_dir = os.path.join('/content/waste-classification-data/DATASET', 'TRAIN')
# test_dir = os.path.join('/content/waste-classification-data/DATASET', 'TEST')

# #Directories set for each of the individual pictures
# #Directories are just defined, for later use to traverse through images and list down each one's content
# train_organic_dir = os.path.join('/content/waste-classification-data/DATASET/TRAIN/O')
# train_recycle_dir = os.path.join('/content/waste-classification-data/DATASET/TRAIN/R')
# test_organic_dir = os.path.join('/content/waste-classification-data/DATASET/TEST/O')
# test_recycle_dir = os.path.join('/content/waste-classification-data/DATASET/TEST/R')

# len(os.listdir(train_organic_dir)) + len(os.listdir(train_recycle_dir))

"""## Creating the CNN ModeL

Checkpoint callback to store training information after every 3 epochs
"""

checkpoint_path = "drive/app/recycleornot/checkpoints/training.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

# Create checkpoint callback
cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, 
                                          save_weights_only=True,
                                                 verbose=1,
                                                 save_freq=3) #save_freq is the non deprecated version of period

"""Build the architecture of the model

Display the details of the created model

Have to compile the model before we can run it, using an optimizer

###Image data generator (define where the images coming from, how much to resize, what to change to, batch size, etc)
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data
test_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data

train_data_gen = train_image_generator.flow_from_directory(batch_size=256,
                                                           directory=train_dir,
                                                           shuffle=True,
                                                           target_size=(80, 80),
                                                           class_mode='binary')

print(train_data_gen.class_indices)

test_data_gen = test_image_generator.flow_from_directory(batch_size=256,
                                                              directory=test_dir,
                                                              target_size=(80, 80),
                                                              class_mode='binary')

"""### Create the Model"""

def createModel():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(80, 80, 3)),
        tf.keras.layers.MaxPooling2D(2, 2),
        # The second convolution
        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        # The third convolution
        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        # Flatten the results to feed into a DNN
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class (nonrecyclable) and 0 class (recyclable)
        tf.keras.layers.Dense(2, activation='softmax')
    ]
    )
    return model

"""OPTIMIZER"""

model = createModel()

from tensorflow.keras.optimizers import RMSprop

model.compile(loss='binary_crossentropy', #because we dealing with only 2 classes (recyclable or not)
              optimizer=RMSprop(lr=0.001),
              metrics=['acc'])

model.summary()

"""###TensorBoard Setup"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

import datetime
# NEED TO PUT IN HEADING IMPORT

log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

!rm -rf ./logs/ #clear previous run logs

"""###Training the model (WITHOUT AUGMENTATION AND DROPOUTS)"""

history = model.fit( 
      train_data_gen,
      steps_per_epoch=88,  #the more data we have, the higher we can make this
      epochs=15,
      validation_data=test_data_gen,
      validation_steps=9,
      verbose=1,
      callbacks=[tensorboard_callback]) # for using tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/fit

"""### DATA AUGMENTATION

> ONLY AUGMENT TRAINING **PICTURES**
"""

aug_model = createModel()

aug_model.compile(loss='binary_crossentropy', #because we dealing with only 2 classes (recyclable or not)
              optimizer=RMSprop(lr=0.001),
              metrics=['acc'])

aug_train_image_generator = ImageDataGenerator(
                              rescale=1./255,
                              rotation_range=45,
                              width_shift_range=.15,
                              height_shift_range=.15,
                              horizontal_flip=True,
                              zoom_range=0.5
                              ) # Generator for our training data

aug_train_data_gen = aug_train_image_generator.flow_from_directory(batch_size=256,
                                                           directory=train_dir,
                                                           shuffle=True,
                                                           target_size=(80, 80),
                                                           class_mode='binary')

"""Visualizing images"""

def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImages(augmented_images)

"""Training on the augmented dataset"""

aug_history = aug_model.fit( 
      aug_train_data_gen,
      steps_per_epoch=88,  #the more data we have, the higher we can make this
      epochs=15,
      validation_data=test_data_gen,
      validation_steps=9,
      verbose=1,
      callbacks=[tensorboard_callback]) # for using tensorboard

"""### Adding Dropouts"""

def createDropoutModel():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(80, 80, 3)),
        tf.keras.layers.MaxPooling2D(2, 2),
        tf.keras.layers.Dropout(0.2), # The first dropout
        # The second convolution
        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        # The third convolution
        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Dropout(0.2), # The second dropout
        # Flatten the results to feed into a DNN
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class (nonrecyclable) and 0 class (recyclable)
        tf.keras.layers.Dense(1, activation='sigmoid')
    ]
    )
    return model

dropout_model = createDropoutModel()

dropout_model.compile(loss='binary_crossentropy', #because we dealing with only 2 classes (recyclable or not)
              optimizer=RMSprop(lr=0.001),
              metrics=['acc'])

dropout_model.summary()

dropout_history = aug_model.fit( 
      train_data_gen,
      steps_per_epoch=88,  #the more data we have, the higher we can make this
      epochs=15,
      validation_data=test_data_gen,
      validation_steps=9,
      verbose=1,
      callbacks=[tensorboard_callback]) # for using tensorboard

"""## Training the Model (with augmentation and dropouts)"""

aug_drop_model = createDropoutModel()
aug_drop_model.compile(loss='binary_crossentropy', #because we dealing with only 2 classes (recyclable or not)
                       optimizer=RMSprop(lr=0.001),
                       metrics=['acc'])

aug_drop_history = aug_drop_model.fit(
      aug_train_data_gen,
      steps_per_epoch=88,  #the more data we have, the higher we can make this
      epochs=15,
      validation_data=test_data_gen,
      validation_steps=9,
      verbose=1,
      callbacks=[tensorboard_callback]) # for using tensorboard)

"""## Comparing accuracies+loss

Replace history with either 
>history, aug_history
,dropout_history
or aug_drop_history
"""

acc = history.history['acc']
val_acc = history.history['val_acc']

loss=history.history['loss']
val_loss=history.history['val_loss']

epochs_range = range(15)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

"""##Making Predictions

Organic = 0
Recyclable = 1
"""

print(train_data_gen.class_indices)

model.summary()

from keras.preprocessing import image

pred_test_dir = '/content/Plastic Bottle Predict.jpg'

test_image = image.load_img(pred_test_dir, target_size=(80,80))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis=0)

test_image = test_image.reshape(1,80,80,3)

result = tf.round(model.predict(test_image, batch_size=1))
print(result)

np.argmax(predictions[0])



"""#SAVING THE MODEL AND THE WEIGHTS
[GUIDE](https://stackoverflow.com/questions/48924165/google-colaboratory-weight-download-export-saved-models)

IF YOU'RE NOT ALREADY MOUNTED TO YOUR GOOGLE DRIVE
"""

# from google.colab import drive
# drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/drive')

model.save_weights('waste_class_weights.h5')
model.save('waste_class_model.h5')

"""# IMPORTING THE MODEL SOMEWHERE ELSE"""

from keras.models import load_model
model = load_model(filePath + 'my_model.h5', 
        custom_objects={'loss':balanced_cross_entropy(0.20)})